# ğŸ¯ ChurnInsight - PredicciÃ³n de CancelaciÃ³n de Clientes Netflix

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/19m1OyDlmwmqMZ4BplVcG4vqvnuR56UlB?usp=sharing)
[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0+-orange.svg)](https://scikit-learn.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ“‹ Tabla de Contenidos

1. [DescripciÃ³n del Proyecto](#-descripciÃ³n-del-proyecto)
2. [Contexto del Problema](#-contexto-del-problema)
3. [Dataset Utilizado](#-dataset-utilizado)
4. [Pipeline ETL - Paso a Paso](#-pipeline-etl---paso-a-paso)
5. [AnÃ¡lisis Exploratorio de Datos (EDA)](#-anÃ¡lisis-exploratorio-de-datos-eda)
6. [DetecciÃ³n de Data Leakage](#-detecciÃ³n-de-data-leakage---problema-crÃ­tico)
7. [SelecciÃ³n de Variables](#-selecciÃ³n-de-variables)
8. [Preprocesamiento de Datos](#-preprocesamiento-de-datos)
9. [Entrenamiento de Modelos](#-entrenamiento-de-modelos)
10. [EvaluaciÃ³n y Resultados](#-evaluaciÃ³n-y-resultados)
11. [AnÃ¡lisis de Impacto Financiero](#-anÃ¡lisis-de-impacto-financiero)
12. [CÃ³mo Usar el Modelo](#-cÃ³mo-usar-el-modelo)
13. [IntegraciÃ³n con API](#-integraciÃ³n-con-api)
14. [Conclusiones](#-conclusiones)

---

## ğŸ“– DescripciÃ³n del Proyecto

**ChurnInsight** es un modelo de Machine Learning diseÃ±ado para predecir la probabilidad de que un cliente de Netflix cancele su suscripciÃ³n (churn). 

### Â¿QuÃ© es Churn?

El **churn** o "tasa de cancelaciÃ³n" es cuando un cliente deja de usar un servicio. En el caso de Netflix, serÃ­a un usuario que cancela su suscripciÃ³n. Predecir quÃ© clientes van a cancelar nos permite contactarlos antes y ofrecerles incentivos para que se queden.

### Objetivo Principal

Desarrollar un modelo capaz de:
- âœ… Identificar clientes en riesgo de cancelaciÃ³n
- âœ… Permitir intervenciones proactivas de retenciÃ³n
- âœ… Maximizar el Lifetime Value (LTV) de la base de usuarios
- âœ… Generar valor econÃ³mico real para el negocio

**ğŸ”— Notebook completo:** [Abrir en Google Colab](https://colab.research.google.com/drive/19m1OyDlmwmqMZ4BplVcG4vqvnuR56UlB?usp=sharing)

---

## ğŸ¢ Contexto del Problema

La industria del entretenimiento por suscripciÃ³n enfrenta un desafÃ­o constante: **reducir la pÃ©rdida de clientes** en un entorno altamente competitivo.

### Â¿Por quÃ© es importante?

| Dato | Impacto |
|------|---------|
| Costo de adquirir cliente nuevo | 5-25 veces mÃ¡s caro que retener uno existente |
| Tasa de churn tÃ­pica en streaming | 2-5% mensual |
| Impacto en ingresos | Cada cliente perdido = pÃ©rdida de ingresos futuros |

### Beneficio de predecir churn

Si podemos identificar clientes que van a cancelar **antes** de que lo hagan, podemos:
1. Contactarlos proactivamente
2. Ofrecerles descuentos o beneficios
3. Resolver sus problemas
4. Retenerlos y mantener sus pagos futuros

---

## ğŸ“Š Dataset Utilizado

Se utiliza el dataset **"Netflix Customer Churn"** disponible en Kaggle.

### CaracterÃ­sticas Generales

| CaracterÃ­stica | Valor |
|----------------|-------|
| Total de registros | 5,000 clientes |
| Total de columnas | 14 variables |
| Variable objetivo | `churned` (1 = cancelÃ³, 0 = permaneciÃ³) |
| Tasa de churn | 50.3% |
| Valores nulos | 0 (dataset limpio) |

### Variables Originales del Dataset

| Variable | DescripciÃ³n | Tipo |
|----------|-------------|------|
| `customer_id` | Identificador Ãºnico del cliente | String |
| `age` | Edad del cliente (18-70 aÃ±os) | NumÃ©rica |
| `gender` | GÃ©nero (Male, Female, Other) | CategÃ³rica |
| `subscription_type` | Tipo de plan (Basic, Standard, Premium) | CategÃ³rica |
| `watch_hours` | Horas totales de visualizaciÃ³n | NumÃ©rica |
| `last_login_days` | DÃ­as desde el Ãºltimo login | NumÃ©rica |
| `region` | RegiÃ³n geogrÃ¡fica (6 regiones) | CategÃ³rica |
| `device` | Dispositivo principal (5 tipos) | CategÃ³rica |
| `monthly_fee` | Cuota mensual ($8.99-$17.99) | NumÃ©rica |
| `payment_method` | MÃ©todo de pago (5 mÃ©todos) | CategÃ³rica |
| `number_of_profiles` | NÃºmero de perfiles en la cuenta | NumÃ©rica |
| `avg_watch_time_per_day` | Promedio de horas diarias | NumÃ©rica |
| `favorite_genre` | GÃ©nero favorito (7 gÃ©neros) | CategÃ³rica |
| `churned` | Si el cliente cancelÃ³ (1) o no (0) | Booleana |

---

## ğŸ”„ Pipeline ETL - Paso a Paso

ETL significa **Extract, Transform, Load** (Extraer, Transformar, Cargar). Es el proceso de preparar los datos para el modelo.

### Paso 1: ExtracciÃ³n (Extract)

```python
# Cargamos el dataset desde GitHub
url = "https://raw.githubusercontent.com/.../netflix_churn.csv"
df = pd.read_csv(url)
```

**Â¿QuÃ© hicimos?**
- Cargamos el dataset directamente desde un repositorio GitHub
- Esto garantiza que cualquier persona pueda reproducir el anÃ¡lisis
- Verificamos que se cargaron 5,000 registros correctamente

### Paso 2: TransformaciÃ³n (Transform)

**2.1 CreaciÃ³n de identificador pÃºblico:**
```python
# Crear public_id anonimizado con hash SHA-256
df['public_id'] = df['customer_id'].apply(
    lambda x: "CUS-" + hashlib.sha256(x.encode()).hexdigest()[:8].upper()
)
```

**Â¿Por quÃ©?** Para proteger la identidad de los clientes pero mantener trazabilidad.

**2.2 ConversiÃ³n de tipos de datos:**
```python
# Convertir categÃ³ricas a tipo 'category' (ahorra memoria)
for col in ['gender', 'subscription_type', 'region', 'device', 'payment_method']:
    df[col] = df[col].astype('category')

# Convertir churned de int a boolean
df['churned'] = df['churned'].astype(bool)
```

**Â¿Por quÃ©?** 
- El tipo `category` usa menos memoria y es mÃ¡s eficiente
- El tipo `bool` es mÃ¡s semÃ¡nticamente correcto para SÃ­/No

**2.3 ValidaciÃ³n de calidad:**
```python
# Verificar duplicados
duplicados = df.duplicated().sum()  # Resultado: 0

# Verificar valores nulos
nulos = df.isnull().sum().sum()  # Resultado: 0
```

### Paso 3: Carga (Load)

El dataset transformado queda listo en memoria para el anÃ¡lisis y modelado.

**Resultado del ETL:**
- âœ… 5,000 registros validados
- âœ… 0 duplicados
- âœ… 0 valores nulos
- âœ… Tipos de datos optimizados
- âœ… Identificador pÃºblico creado

---

## ğŸ“ˆ AnÃ¡lisis Exploratorio de Datos (EDA)

El EDA nos permite entender los datos antes de construir el modelo.

### 5.1 DistribuciÃ³n de la Variable Objetivo

```python
df['churned'].value_counts(normalize=True) * 100
```

| Estado | Porcentaje | Cantidad |
|--------|------------|----------|
| Churned (True) | 50.3% | 2,515 |
| Retained (False) | 49.7% | 2,485 |

**âš ï¸ Nota importante:** Una tasa de churn del 50% es irreal para streaming (lo tÃ­pico es 2-5%). Esto indica que el dataset es **sintÃ©tico/balanceado artificialmente** para entrenamiento.

### 5.2 DistribuciÃ³n de Variables CategÃ³ricas

| Variable | DistribuciÃ³n |
|----------|--------------|
| `gender` | Female: 34.2%, Male: 33.1%, Other: 32.7% |
| `subscription_type` | Premium: 33.9%, Basic: 33.2%, Standard: 32.9% |
| `region` | ~16-17% cada una (6 regiones) |
| `device` | ~19-21% cada uno (5 dispositivos) |
| `payment_method` | ~19-21% cada uno (5 mÃ©todos) |

**ObservaciÃ³n:** Las variables categÃ³ricas estÃ¡n **uniformemente distribuidas**, lo cual es otra seÃ±al de que el dataset es sintÃ©tico.

### 5.3 DistribuciÃ³n de Variables NumÃ©ricas

| Variable | Media | Desv. Est. | MÃ­n | MÃ¡x |
|----------|-------|------------|-----|-----|
| `age` | 43.9 | 15.3 | 18 | 70 |
| `watch_hours` | 11.6 | 8.4 | 0.0 | 30.0 |
| `number_of_profiles` | 3.0 | 1.4 | 1 | 5 |
| `last_login_days` | 30.0 | 12.9 | 1 | 60 |

---

## âš ï¸ DetecciÃ³n de Data Leakage - Problema CrÃ­tico

### Â¿QuÃ© es Data Leakage?

**Data Leakage** (fuga de datos) ocurre cuando el modelo utiliza informaciÃ³n que **no estarÃ­a disponible** al momento de hacer predicciones en producciÃ³n. Es como hacer trampa: el modelo "ve las respuestas" durante el entrenamiento.

### Â¿CÃ³mo lo detectamos?

Comparamos el promedio de cada variable entre clientes que cancelaron vs los que permanecieron:

```python
# CÃ³digo de detecciÃ³n
for col in ['last_login_days', 'avg_watch_time_per_day', 'watch_hours', 'number_of_profiles']:
    mean_churned = df[df['churned']==True][col].mean()
    mean_retained = df[df['churned']==False][col].mean()
    ratio = mean_churned / mean_retained
    
    # Si el ratio es muy diferente de 1, hay leakage
    if ratio > 2.0 or ratio < 0.5:
        print(f"âš ï¸ LEAKAGE en {col}")
```

### Resultados del AnÃ¡lisis

| Variable | Churned | Retained | Ratio | Â¿Leakage? |
|----------|---------|----------|-------|-----------|
| `last_login_days` | 38.3 dÃ­as | 21.8 dÃ­as | 1.76 | ğŸ”´ **SÃ** |
| `avg_watch_time_per_day` | 0.2 hrs | 1.6 hrs | 0.10 | ğŸ”´ **SÃ** |
| `watch_hours` | 5.9 hrs | 17.4 hrs | 0.34 | ğŸ”´ **SÃ** |
| `number_of_profiles` | 2.8 | 3.3 | 0.86 | ğŸŸ¢ **NO** |

### Â¿Por quÃ© `last_login_days` es Leakage?

**ExplicaciÃ³n con ejemplo:**

Imagina a Juan, cliente de Netflix:
1. Juan estÃ¡ pensando en cancelar (pero aÃºn no lo ha hecho)
2. Como estÃ¡ descontento, deja de usar Netflix
3. Pasan 40 dÃ­as sin que entre a la plataforma
4. Finalmente, Juan cancela su suscripciÃ³n

**El problema:** La variable `last_login_days` (40 dÃ­as) es una **CONSECUENCIA** de que Juan va a cancelar, no una **CAUSA**. El cliente deja de usar la plataforma ANTES de cancelar.

**En producciÃ³n:** Cuando queremos predecir si un cliente va a cancelar, no podemos saber cuÃ¡ntos dÃ­as pasarÃ¡n sin que use la app, porque eso aÃºn no ha ocurrido.

### AnalogÃ­a Simple

> Es como predecir que va a llover mirando el suelo mojado. TÃ©cnicamente aciertas, pero no sirve para decidir si llevar paraguas.
>
> **Modelo con leakage:** Mira el suelo mojado â†’ Predice lluvia (inÃºtil)
>
> **Modelo correcto:** Mira las nubes y humedad â†’ Predice lluvia (Ãºtil)

### Impacto del Leakage

| MÃ©trica | Con Leakage | Sin Leakage |
|---------|-------------|-------------|
| Accuracy | ~97% (falso) | ~77% (real) |
| Recall | ~98% (artificial) | ~86% (genuino) |
| Â¿Funciona en producciÃ³n? | âŒ NO | âœ… SÃ |

---

## ğŸ¯ SelecciÃ³n de Variables

BasÃ¡ndonos en el anÃ¡lisis de Data Leakage, seleccionamos cuidadosamente las variables.

### Variables EXCLUIDAS (con justificaciÃ³n detallada)

| Variable | Â¿Por quÃ© se excluyÃ³? |
|----------|----------------------|
| `last_login_days` | **DATA LEAKAGE** - Es consecuencia del churn, no causa. El cliente deja de usar la app ANTES de cancelar. Ratio 1.76 indica separaciÃ³n artificial. |
| `avg_watch_time_per_day` | **DATA LEAKAGE + Redundancia** - Ratio 0.10 (muy alejado de 1). AdemÃ¡s, es derivable de `watch_hours`. |
| `monthly_fee` | **Variable derivada** - El precio estÃ¡ 100% determinado por `subscription_type`: Basic=$8.99, Standard=$13.99, Premium=$17.99. Incluir ambas genera redundancia. |
| `favorite_genre` | **Alta cardinalidad, bajo poder predictivo** - 7 categorÃ­as con distribuciÃ³n uniforme (~14% cada una). No correlaciona con churn. |
| `customer_id` | **Identificador Ãºnico** - Solo sirve para identificar registros, no tiene valor predictivo. |
| `public_id` | **Identificador Ãºnico** - Hash generado del customer_id, sin valor predictivo. |

### Variables INCLUIDAS (8 features)

| Variable | Tipo | Â¿Por quÃ© se incluyÃ³? |
|----------|------|----------------------|
| `age` | NumÃ©rica | Factor demogrÃ¡fico estable. La edad puede influir en patrones de consumo y no cambia por comportamiento del cliente. |
| `watch_hours` | NumÃ©rica | Representa el **engagement total** del cliente. Es informaciÃ³n histÃ³rica disponible antes de la predicciÃ³n. |
| `number_of_profiles` | NumÃ©rica | Indica cuÃ¡ntas personas usan la cuenta. MÃ¡s perfiles = mayor compromiso familiar = menor probabilidad de cancelar. |
| `gender` | CategÃ³rica | Factor demogrÃ¡fico que puede correlacionar con preferencias y permanencia. |
| `subscription_type` | CategÃ³rica | El tipo de plan (Basic, Standard, Premium) refleja el nivel de inversiÃ³n del cliente en el servicio. |
| `region` | CategÃ³rica | La ubicaciÃ³n puede influir en disponibilidad de contenido y competencia local. |
| `payment_method` | CategÃ³rica | El mÃ©todo de pago puede indicar facilidad de cancelaciÃ³n (ej: tarjeta de crÃ©dito vs dÃ©bito automÃ¡tico). |
| `device` | CategÃ³rica | El dispositivo puede indicar nivel de integraciÃ³n del servicio en la vida del cliente (TV vs mÃ³vil). |

### CÃ³digo de SelecciÃ³n

```python
# Variables seleccionadas
X = df[["age", "gender", "subscription_type", "watch_hours", "region",
        "number_of_profiles", "payment_method", "device"]]
y = df["churned"]

print(f"âœ… Variables INCLUIDAS: {list(X.columns)}")
print(f"ğŸš« Variables EXCLUIDAS: ['last_login_days', 'avg_watch_time_per_day', 'monthly_fee', 'favorite_genre']")
```

---

## âš™ï¸ Preprocesamiento de Datos

Los modelos de Machine Learning no pueden procesar texto directamente. Necesitamos transformar los datos.

### 8.1 DivisiÃ³n Train/Test

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2,      # 20% para test
    random_state=42,    # Reproducibilidad
    stratify=y          # Mantener proporciÃ³n de clases
)
```

| Conjunto | Registros | Porcentaje |
|----------|-----------|------------|
| Train | 4,000 | 80% |
| Test | 1,000 | 20% |

**Â¿QuÃ© es `stratify=y`?** Asegura que la proporciÃ³n de churned/retained sea la misma en train y test (50.3%/49.7%).

### 8.2 TransformaciÃ³n de Variables

**Variables NumÃ©ricas â†’ StandardScaler**

```python
from sklearn.preprocessing import StandardScaler

# StandardScaler transforma: (valor - media) / desviaciÃ³n_estÃ¡ndar
# Resultado: media=0, desv_std=1
```

**Â¿Por quÃ©?** Algunos algoritmos (como Logistic Regression) funcionan mejor cuando todas las variables numÃ©ricas estÃ¡n en la misma escala.

**Ejemplo:**
| Variable | Original | Escalada |
|----------|----------|----------|
| `age` | 35 aÃ±os | -0.58 |
| `watch_hours` | 15.5 hrs | 0.46 |

**Variables CategÃ³ricas â†’ OneHotEncoder**

```python
from sklearn.preprocessing import OneHotEncoder

# OneHotEncoder convierte categorÃ­as en columnas binarias (0/1)
# drop='first' elimina una categorÃ­a para evitar multicolinealidad
```

**Ejemplo con `gender`:**

| gender_Female | gender_Male | (gender_Other es la referencia) |
|---------------|-------------|--------------------------------|
| 1 | 0 | Si es Female |
| 0 | 1 | Si es Male |
| 0 | 0 | Si es Other |

**Â¿QuÃ© es `drop='first'`?** Elimina la primera categorÃ­a para evitar la **"trampa de variables dummy"** (multicolinealidad). Si sabemos que no es Female ni Male, entonces es Other.

### 8.3 Pipeline de Preprocesamiento Completo

```python
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder

num_features = ["age", "watch_hours", "number_of_profiles"]
cat_features = ["gender", "subscription_type", "region", "payment_method", "device"]

preprocess = ColumnTransformer(
    transformers=[
        ("num", StandardScaler(), num_features),
        ("cat", OneHotEncoder(handle_unknown='ignore', drop='first'), cat_features)
    ]
)
```

---

## ğŸ¤– Entrenamiento de Modelos

### 9.1 Modelos Seleccionados

Evaluamos 3 algoritmos diferentes:

| Modelo | DescripciÃ³n | Ventajas |
|--------|-------------|----------|
| **Logistic Regression** | Modelo lineal que predice probabilidades | Interpretable, rÃ¡pido, buen baseline |
| **Decision Tree** | Ãrbol de decisiones | FÃ¡cil de visualizar, captura no-linealidades |
| **Random Forest** | Conjunto de Ã¡rboles | Robusto, reduce overfitting |

### 9.2 Â¿QuÃ© es ValidaciÃ³n Cruzada?

En lugar de dividir los datos una sola vez, dividimos en **5 partes (folds)**:

```
Fold 1: [Test] [Train] [Train] [Train] [Train]
Fold 2: [Train] [Test] [Train] [Train] [Train]
Fold 3: [Train] [Train] [Test] [Train] [Train]
Fold 4: [Train] [Train] [Train] [Test] [Train]
Fold 5: [Train] [Train] [Train] [Train] [Test]
```

**Â¿Por quÃ©?** Obtenemos mÃ©tricas mÃ¡s confiables al probar en 5 conjuntos diferentes.

```python
from sklearn.model_selection import StratifiedKFold

cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
```

### 9.3 BÃºsqueda de HiperparÃ¡metros

Los modelos tienen "perillas" llamadas **hiperparÃ¡metros** que afectan su comportamiento.

```python
from sklearn.model_selection import RandomizedSearchCV

# Ejemplo para Logistic Regression
param_logreg = {
    "model__C": np.logspace(-4, 4, 20),  # RegularizaciÃ³n
    "model__penalty": ["l1", "l2"],       # Tipo de penalizaciÃ³n
    "model__solver": ["liblinear"]        # Algoritmo de optimizaciÃ³n
}

rand_search = RandomizedSearchCV(
    pipe,
    param_logreg,
    n_iter=15,           # Probar 15 combinaciones
    cv=cv_strategy,      # ValidaciÃ³n cruzada 5-fold
    scoring=f2_scorer,   # MÃ©trica a optimizar
    n_jobs=-1,           # Usar todos los CPUs
    random_state=42
)
```

### 9.4 Â¿Por quÃ© F2-Score como MÃ©trica?

**Las mÃ©tricas tradicionales:**

| MÃ©trica | FÃ³rmula | Â¿QuÃ© mide? |
|---------|---------|------------|
| **Precision** | TP / (TP + FP) | De los que predije como churn, Â¿cuÃ¡ntos realmente eran? |
| **Recall** | TP / (TP + FN) | De los que realmente eran churn, Â¿cuÃ¡ntos detectÃ©? |
| **F1-Score** | 2 Ã— (Prec Ã— Rec) / (Prec + Rec) | Balance entre Precision y Recall |

**El problema:** F1-Score trata Precision y Recall como igualmente importantes. Pero en churn **no lo son**.

**F2-Score:** Pesa el Recall **2 veces mÃ¡s** que la Precision.

```python
from sklearn.metrics import fbeta_score, make_scorer

# F2-Score: beta=2 significa Recall es 2x mÃ¡s importante
f2_scorer = make_scorer(fbeta_score, beta=2)
```

**Â¿Por quÃ© priorizar Recall?**

| Error | Nombre | Costo | Consecuencia |
|-------|--------|-------|--------------|
| No detectar churner | False Negative (FN) | **$120** | Perdemos al cliente para siempre |
| Falsa alarma | False Positive (FP) | **$10** | Solo gastamos en una oferta innecesaria |

Es **12 veces mÃ¡s costoso** no detectar un churner que tener una falsa alarma.

### 9.5 Mejores HiperparÃ¡metros Encontrados

| Modelo | Mejores ParÃ¡metros |
|--------|-------------------|
| **Logistic Regression** | `C=0.00483, penalty=l2, solver=liblinear` |
| **Decision Tree** | `max_depth=3, min_samples_split=20, min_samples_leaf=8, criterion=gini` |
| **Random Forest** | `n_estimators=200, max_depth=20, min_samples_split=2, max_features=log2` |

---

## ğŸ“Š EvaluaciÃ³n y Resultados

### 10.1 ComparaciÃ³n de Modelos

| Modelo | Accuracy | Precision | Recall | F1-Score | F2-Score | ROC-AUC |
|--------|----------|-----------|--------|----------|----------|---------|
| **Logistic Regression** | **76.9%** | **73.0%** | **85.9%** | **78.9%** | **83.0%** | **85.0%** |
| Decision Tree | 73.5% | 68.8% | 86.5% | 76.7% | 82.3% | 83.2% |
| Random Forest | 76.2% | 76.5% | 76.1% | 76.3% | 76.2% | 86.5% |

**Modelo ganador: Logistic Regression** ğŸ†

**Â¿Por quÃ©?**
- Mayor F2-Score (83.0%)
- Excelente Recall (85.9%) - detecta la mayorÃ­a de churners
- Modelo mÃ¡s interpretable
- Menor riesgo de overfitting

### 10.2 Matriz de ConfusiÃ³n

La matriz de confusiÃ³n muestra los 4 resultados posibles:

```
              PredicciÃ³n del Modelo
              No Churn    Churn
Realidad  No    337        160     (497 clientes leales)
          SÃ­     71        432     (503 clientes churners)
```

| Resultado | Cantidad | Significado |
|-----------|----------|-------------|
| **TN (337)** | True Negative | âœ… Clientes leales que predijimos como leales |
| **FP (160)** | False Positive | âš ï¸ Clientes leales que predijimos como churners (falsa alarma) |
| **FN (71)** | False Negative | âŒ Churners que NO detectamos (se van sin intervenciÃ³n) |
| **TP (432)** | True Positive | âœ… Churners que detectamos correctamente |

### 10.3 InterpretaciÃ³n de MÃ©tricas

**Recall = 85.9%**
```
Recall = TP / (TP + FN) = 432 / (432 + 71) = 85.9%
```
De los 503 clientes que realmente cancelaron, detectamos 432 (85.9%).

**Precision = 73.0%**
```
Precision = TP / (TP + FP) = 432 / (432 + 160) = 73.0%
```
De los 592 clientes que predijimos como churners, 432 realmente lo eran (73.0%).

**Accuracy = 76.9%**
```
Accuracy = (TN + TP) / Total = (337 + 432) / 1000 = 76.9%
```
En general, acertamos en el 76.9% de los casos.

---

## ğŸ’° AnÃ¡lisis de Impacto Financiero

### 11.1 Â¿QuÃ© es LTV (Lifetime Value)?

El **LTV (Lifetime Value)** o "Valor de Vida del Cliente" es el **total de ingresos que un cliente genera durante toda su relaciÃ³n con la empresa**.

**CÃ¡lculo del LTV para Netflix:**

| Concepto | Valor |
|----------|-------|
| Pago mensual promedio | $15 |
| Meses promedio de permanencia | 8 meses |
| **LTV** | **$120** ($15 Ã— 8 meses) |

> Cada cliente que perdemos representa **$120 de ingresos futuros perdidos**.

### 11.2 Supuestos de Negocio

| Concepto | Valor | ExplicaciÃ³n |
|----------|-------|-------------|
| **Costo FN** | $120 | LTV perdido al no detectar un churner |
| **Costo FP** | $10 | Costo de enviar oferta de retenciÃ³n innecesaria |
| **Beneficio TP** | $80 | LTV recuperado ($120) menos costo de retenciÃ³n ($40) |

**Â¿Por quÃ© el beneficio TP es $80 y no $120?**
- No todos los clientes contactados aceptan quedarse (~70% de Ã©xito)
- Gastamos dinero en la oferta de retenciÃ³n (descuentos, promociones)
- $120 - $40 = $80 de beneficio neto

### 11.3 CÃ¡lculo del Impacto Financiero

| Resultado | Cantidad | Ã— | Costo/Beneficio | = | Total |
|-----------|----------|---|-----------------|---|-------|
| Churners no detectados (FN) | 71 | Ã— | -$120 | = | **-$8,520** |
| Falsas alarmas (FP) | 160 | Ã— | -$10 | = | **-$1,600** |
| Churners retenidos (TP) | 432 | Ã— | +$80 | = | **+$34,560** |
| **BALANCE NETO** | | | | = | **+$24,440** |

### 11.4 InterpretaciÃ³n

âœ… **El modelo genera +$24,440 de valor por cada 1,000 clientes evaluados**

**ProyecciÃ³n a escala:**

| Base de clientes | Valor generado |
|------------------|----------------|
| 1,000 clientes | +$24,440 |
| 10,000 clientes | +$244,400 |
| 100,000 clientes | +$2,444,000 |
| 1,000,000 clientes | +$24,440,000 |

---

## ğŸš€ CÃ³mo Usar el Modelo

### 12.1 Requisitos

```bash
pip install pandas numpy scikit-learn joblib
```

### 12.2 Cargar y Usar el Modelo

```python
import joblib
import pandas as pd

# Cargar el modelo entrenado
model = joblib.load('churn_model_final.joblib')

# Datos de un nuevo cliente
nuevo_cliente = pd.DataFrame({
    'age': [35],
    'gender': ['Female'],
    'subscription_type': ['Premium'],
    'watch_hours': [45.5],
    'region': ['North America'],
    'number_of_profiles': [3],
    'payment_method': ['Credit Card'],
    'device': ['TV']
})

# Hacer predicciÃ³n
prediccion = model.predict(nuevo_cliente)
probabilidad = model.predict_proba(nuevo_cliente)

# Mostrar resultados
print(f"PredicciÃ³n: {'CHURN âš ï¸' if prediccion[0] else 'NO CHURN âœ…'}")
print(f"Probabilidad de churn: {probabilidad[0][1]:.1%}")
```

**Ejemplo de salida:**
```
PredicciÃ³n: NO CHURN âœ…
Probabilidad de churn: 15.3%
```

### 12.3 InterpretaciÃ³n de Resultados

| Probabilidad | Riesgo | AcciÃ³n Recomendada |
|--------------|--------|-------------------|
| 0% - 30% | ğŸŸ¢ Bajo | Mantener comunicaciÃ³n normal |
| 30% - 60% | ğŸŸ¡ Medio | Monitorear, enviar encuesta de satisfacciÃ³n |
| 60% - 80% | ğŸŸ  Alto | Contactar proactivamente, ofrecer beneficios |
| 80% - 100% | ğŸ”´ CrÃ­tico | IntervenciÃ³n urgente, oferta especial |

---

## ğŸ”Œ IntegraciÃ³n con API

### 13.1 Endpoint Principal

**POST /predict**

```json
// Request
{
  "age": 35,
  "gender": "Female",
  "subscription_type": "Premium",
  "watch_hours": 45.5,
  "region": "North America",
  "number_of_profiles": 3,
  "payment_method": "Credit Card",
  "device": "TV"
}

// Response
{
  "prediction": 0,
  "probabilities": {
    "not_churn": 0.85,
    "churn": 0.15
  }
}
```

### 13.2 Otros Endpoints Disponibles

| Endpoint | MÃ©todo | DescripciÃ³n |
|----------|--------|-------------|
| `/predict` | POST | Predecir churn para nuevo cliente |
| `/item/predictions/{id}` | GET | Predecir para cliente existente por ID |
| `/probability/age` | GET | Probabilidad de churn por grupo de edad |
| `/probability/gender` | GET | Probabilidad de churn por gÃ©nero |
| `/probability/subscription` | GET | Probabilidad de churn por tipo de plan |
| `/probability/region` | GET | Probabilidad de churn por regiÃ³n |

### 13.3 Cambios vs VersiÃ³n Anterior

| Campo | VersiÃ³n Anterior | VersiÃ³n Actual |
|-------|------------------|----------------|
| `last_login_days` | âœ… Requerido | âŒ **ELIMINADO** (leakage) |
| `number_of_profiles` | âŒ No incluido | âœ… **AGREGADO** |
| `payment_method` | âŒ No incluido | âœ… **AGREGADO** |
| `device` | âŒ No incluido | âœ… **AGREGADO** |

---

## ğŸ“ Conclusiones

### 14.1 Logros del Proyecto

| Aspecto | Resultado |
|---------|-----------|
| âœ… Data Leakage | Detectado y eliminado |
| âœ… Modelo funcional | Logistic Regression con 85.9% Recall |
| âœ… Valor de negocio | +$24,440 por cada 1,000 clientes |
| âœ… DocumentaciÃ³n | Completa y reproducible |
| âœ… IntegraciÃ³n | Listo para API REST |

### 14.2 ComparaciÃ³n Final: Modelo Original vs Optimizado

| Aspecto | Original | Optimizado |
|---------|----------|------------|
| Data Leakage | âŒ Presente | âœ… Eliminado |
| Accuracy | 96.5% (falso) | 76.9% (real) |
| Recall | 98% (artificial) | 85.9% (genuino) |
| Features | 6 (con leakage) | 8 (sin leakage) |
| ValidaciÃ³n | Simple | 5-fold estratificada |
| Funciona en producciÃ³n | âŒ NO | âœ… SÃ |

### 14.3 Lecciones Aprendidas

1. **MÃ©tricas altas no siempre son buenas** - El 97% de accuracy era seÃ±al de problema, no de Ã©xito.

2. **Entender el negocio es crucial** - Sin entender que `last_login_days` es consecuencia del churn, no habrÃ­amos detectado el leakage.

3. **F2-Score > Accuracy para churn** - Priorizar detectar churners es mÃ¡s valioso que accuracy general.

4. **El modelo mÃ¡s simple puede ser el mejor** - Logistic Regression superÃ³ a Random Forest.

---

## ğŸ“ Estructura del Proyecto

```
ChurnInsight/
â”œâ”€â”€ ğŸ““ Rdavila_ChurnInsight_ETL_ML_Final.ipynb  # Notebook principal
â”œâ”€â”€ ğŸ“¦ churn_model_final.joblib                 # Modelo entrenado (Logistic Regression)
â”œâ”€â”€ ğŸ“¦ logreg_optimized.joblib                  # Pipeline completo LogReg
â”œâ”€â”€ ğŸ“¦ tree_optimized.joblib                    # Pipeline completo Decision Tree
â”œâ”€â”€ ğŸ“¦ rf_optimized.joblib                      # Pipeline completo Random Forest
â”œâ”€â”€ ğŸ“„ README.md                                # Este archivo
â””â”€â”€ ğŸ“Š data/
    â””â”€â”€ netflix_churn.csv                       # Dataset original
```

---

## ğŸ‘¤ Autor

**R. DÃ¡vila**

- ğŸ“§ Contacto: [Tu email]
- ğŸ”— LinkedIn: [Tu LinkedIn]
- ğŸ™ GitHub: [Tu GitHub]

---

## ğŸ™ Agradecimientos

- **Dataset:** [Netflix Customer Churn - Kaggle](https://www.kaggle.com/)
- **Hackathon:** NoCountry
- **Equipo:** DracoStack

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

<p align="center">
  <b>â­ Si este proyecto te fue Ãºtil, considera darle una estrella en GitHub â­</b>
</p>
